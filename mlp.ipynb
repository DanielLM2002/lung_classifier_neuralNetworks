{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, ops\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'COVID-19_Radiography_Dataset'\n",
    "train_dir = os.path.join(root_dir, 'lbp', 'train')\n",
    "val_dir = os.path.join(root_dir, 'lbp', 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key=os.getenv('WANDB_KEY'))\n",
    "wandb.init(project='COVID-19_Radiography_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script shown below calculates the mean and standard deviation for the training set. These values are then used to apply the standarization to the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(train_dir, transform=Grayscale())\n",
    "loader = DataLoader(dataset, 64, shuffle=True)\n",
    "\n",
    "# Initialize variables for mean and std calculation\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data, _ in loader:\n",
    "    data = data.to(device)\n",
    "    batch_samples = data.size(0)  # number of images in the batch\n",
    "    data = data.view(batch_samples, -1)  # flatten the channel and spatial dimensions\n",
    "    mean += data.mean(1).sum(0)\n",
    "    std += data.std(1).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These transforms are applied for standarization and data augmentation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "        transforms.RandomRotation(10),  # Randomly rotate the image by up to 10 degrees\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),  # Randomly change brightness, contrast, saturation, and hue\n",
    "        # transforms.Normalize(mean=0.0197, std=0.0083)  # Normalize the image (uniform LBP)\n",
    "        transforms.Normalize(mean=0.6133, std=0.3372)  # Normalize the image (default LBP)\n",
    "        # transforms.Normalize(mean=0.2283, std=0.3103)  # Normalize the image (ror LBP)\n",
    "        # transforms.Normalize(mean=0.0772, std=0.1784)  # Normalize the image (var LBP)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Grayscale(),\n",
    "        # transforms.Normalize(mean=0.0197, std=0.0083)  # Normalize the (uniform LBP)\n",
    "        transforms.Normalize(mean=0.6133, std=0.3372)  # Normalize the image (default LBP)\n",
    "        # transforms.Normalize(mean=0.2283, std=0.3103)  # Normalize the image (ror LBP)\n",
    "        # transforms.Normalize(mean=0.0772, std=0.1784)  # Normalize the image (var LBP)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP PyTorch module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim, hidden_layers=[128], activation='relu', dropout=0):\n",
    "    super(MLP, self).__init__()\n",
    "\n",
    "    if activation == \"relu\":\n",
    "      activation_func = lambda: nn.ReLU()\n",
    "    elif activation == \"prelu\":\n",
    "      activation_func = lambda: nn.PReLU()\n",
    "    # You can add other activation functions here\n",
    "    else:\n",
    "      raise NotImplementedError(\"Activation function not supported\")\n",
    "\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.input_layer = nn.Linear(input_dim, hidden_layers[0])\n",
    "    self.input_activation = activation_func()\n",
    "\n",
    "    self.hidden_layers = nn.ModuleList([])\n",
    "    for index in range(len(hidden_layers)):\n",
    "        next = index + 1\n",
    "        if next < len(hidden_layers):\n",
    "          self.hidden_layers.append(nn.Linear(hidden_layers[index], hidden_layers[next]))\n",
    "          self.hidden_layers.append(nn.BatchNorm1d(hidden_layers[next]))\n",
    "        else:\n",
    "          self.hidden_layers.append(nn.Linear(hidden_layers[index], hidden_layers[index]))\n",
    "          self.hidden_layers.append(nn.BatchNorm1d(hidden_layers[index]))\n",
    "        self.hidden_layers.append(activation_func())\n",
    "        if dropout > 0:\n",
    "          self.hidden_layers.append(nn.Dropout(dropout))\n",
    "\n",
    "    self.output_layer = nn.Linear(hidden_layers[-1], output_dim)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    x = self.input_layer(x)\n",
    "    x = self.input_activation(x)\n",
    "\n",
    "    for layer in self.hidden_layers:\n",
    "      x = layer(x)\n",
    "\n",
    "    x = self.output_layer(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions and initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_features = 299 * 299\n",
    "hidden_layers = [256, 256]\n",
    "num_classes = 4\n",
    "dropout = 0.5\n",
    "activation = 'prelu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = MLP(input_dim=input_features,\n",
    "            hidden_layers=hidden_layers,\n",
    "            output_dim=num_classes,\n",
    "            dropout=dropout,\n",
    "            activation=activation).to(device)\n",
    "\n",
    "# Define loss function and optimizer (replace with your choices)\n",
    "criterion = nn.CrossEntropyLoss()  # Assuming classification task\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 15\n",
    "best_val_loss, epochs_no_improve = 0, 0\n",
    "patience = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.train()\n",
    "  \n",
    "  train_progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", unit=\"batch\")\n",
    "  for inputs, labels in train_progress:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_progress.set_postfix({\"Loss\": running_loss / total, \"Acc\": correct / total})\n",
    "\n",
    "  epoch_loss = running_loss / len(train_loader.dataset)\n",
    "  epoch_acc = correct / total\n",
    "\n",
    "  print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "  print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "  # wandb.log({\"epoch\": epoch + 1, \"train_loss\": epoch_loss, \"train_accuracy\": epoch_acc})\n",
    "\n",
    "  model.eval()\n",
    "  val_loss = 0.0\n",
    "  val_correct = 0\n",
    "  val_total = 0\n",
    "\n",
    "  # Validation phase with progress bar\n",
    "  val_progress = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\", unit=\"batch\")\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in val_progress:\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      val_loss += loss.item() * inputs.size(0)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      val_total += labels.size(0)\n",
    "      val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "      val_progress.set_postfix({\"Loss\": val_loss / val_total, \"Acc\": val_correct / val_total})\n",
    "\n",
    "  val_loss = val_loss / len(val_loader.dataset)\n",
    "  val_acc = val_correct / val_total\n",
    "\n",
    "  print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "  # wandb.log({\"epoch\": epoch + 1, \"val_loss\": val_loss, \"val_accuracy\": val_acc})\n",
    "\n",
    "  # Check for improvement\n",
    "  if val_loss < best_val_loss:\n",
    "    best_val_loss = val_loss\n",
    "    epochs_no_improve = 0\n",
    "  else:\n",
    "    epochs_no_improve += 1\n",
    "\n",
    "  if epochs_no_improve >= patience:\n",
    "    print(\"Early stopping triggered!\")\n",
    "    break\n",
    "\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
