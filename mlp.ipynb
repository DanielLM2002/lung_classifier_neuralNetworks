{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, ops\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'COVID-19_Radiography_Dataset'\n",
    "train_dir = os.path.join(root_dir, 'lbp', 'train')\n",
    "val_dir = os.path.join(root_dir, 'lbp', 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login(key=os.getenv('WANDB_KEY'))\n",
    "wandb.init(project='mlp_local_binary_patterns', name='LBP default - no aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The script shown below calculates the mean and standard deviation for the training set. These values are then used to apply the standarization to the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(train_dir, transform=Grayscale())\n",
    "loader = DataLoader(dataset, 64, shuffle=True)\n",
    "\n",
    "# Initialize variables for mean and std calculation\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "nb_samples = 0\n",
    "\n",
    "for data, _ in loader:\n",
    "    data = data.to(device)\n",
    "    batch_samples = data.size(0)  # number of images in the batch\n",
    "    data = data.view(batch_samples, -1)  # flatten the channel and spatial dimensions\n",
    "    mean += data.mean(1).sum(0)\n",
    "    std += data.std(1).sum(0)\n",
    "    nb_samples += batch_samples\n",
    "\n",
    "mean /= nb_samples\n",
    "std /= nb_samples\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Std:\", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These transforms are applied for standarization and data augmentation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        # transforms.RandomResizedCrop(size=299, scale=(0.8, 1.0)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=0.0197, std=0.0083)  # Normalize the image (uniform LBP)\n",
    "        transforms.Normalize(mean=0.6133, std=0.3372)  # Normalize the image (default LBP)\n",
    "        # transforms.Normalize(mean=0.2283, std=0.3103)  # Normalize the image (ror LBP)\n",
    "        # transforms.Normalize(mean=0.0772, std=0.1784)  # Normalize the image (var LBP)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Grayscale(),\n",
    "        # transforms.Normalize(mean=0.0197, std=0.0083)  # Normalize the (uniform LBP)\n",
    "        transforms.Normalize(mean=0.6133, std=0.3372)  # Normalize the image (default LBP)\n",
    "        # transforms.Normalize(mean=0.2283, std=0.3103)  # Normalize the image (ror LBP)\n",
    "        # transforms.Normalize(mean=0.0772, std=0.1784)  # Normalize the image (var LBP)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP PyTorch module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self, input_dim, output_dim, hidden_layers=[128], activation='relu', dropout=0):\n",
    "    super(MLP, self).__init__()\n",
    "\n",
    "    if activation == \"relu\":\n",
    "      activation_func = lambda: nn.ReLU()\n",
    "    elif activation == \"prelu\":\n",
    "      activation_func = lambda: nn.PReLU()\n",
    "    # You can add other activation functions here\n",
    "    else:\n",
    "      raise NotImplementedError(\"Activation function not supported\")\n",
    "\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.input_layer = nn.Linear(input_dim, hidden_layers[0])\n",
    "    self.input_activation = activation_func()\n",
    "\n",
    "    self.hidden_layers = nn.ModuleList([])\n",
    "    for index in range(len(hidden_layers)):\n",
    "        next = index + 1\n",
    "        if next < len(hidden_layers):\n",
    "          self.hidden_layers.append(nn.Linear(hidden_layers[index], hidden_layers[next]))\n",
    "          self.hidden_layers.append(nn.BatchNorm1d(hidden_layers[next]))\n",
    "        else:\n",
    "          self.hidden_layers.append(nn.Linear(hidden_layers[index], hidden_layers[index]))\n",
    "          self.hidden_layers.append(nn.BatchNorm1d(hidden_layers[index]))\n",
    "        self.hidden_layers.append(activation_func())\n",
    "        if dropout > 0:\n",
    "          self.hidden_layers.append(nn.Dropout(dropout))\n",
    "\n",
    "    self.output_layer = nn.Linear(hidden_layers[-1], output_dim)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    x = self.input_layer(x)\n",
    "    x = self.input_activation(x)\n",
    "\n",
    "    for layer in self.hidden_layers:\n",
    "      x = layer(x)\n",
    "\n",
    "    x = self.output_layer(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions and initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "input_features = 299 * 299\n",
    "hidden_layers = [256, 256]\n",
    "num_classes = 4\n",
    "dropout = 0.5\n",
    "activation = 'prelu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=data_transforms['train'])\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=data_transforms['val'])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "model = MLP(input_dim=input_features,\n",
    "            hidden_layers=hidden_layers,\n",
    "            output_dim=num_classes,\n",
    "            dropout=dropout,\n",
    "            activation=activation).to(device)\n",
    "\n",
    "# Define loss function and optimizer (replace with your choices)\n",
    "criterion = nn.CrossEntropyLoss()  # Assuming classification task\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Training: 100%|██████████| 265/265 [02:03<00:00,  2.14batch/s, Loss=0.959, Acc=0.597]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "Train Loss: 0.9593 Acc: 0.5966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Validation: 100%|██████████| 67/67 [00:19<00:00,  3.42batch/s, Loss=0.743, Acc=0.704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.7428 Acc: 0.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Training: 100%|██████████| 265/265 [02:01<00:00,  2.18batch/s, Loss=0.798, Acc=0.672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20\n",
      "Train Loss: 0.7983 Acc: 0.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Validation: 100%|██████████| 67/67 [00:19<00:00,  3.35batch/s, Loss=0.665, Acc=0.742]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6647 Acc: 0.7417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Training: 100%|██████████| 265/265 [02:02<00:00,  2.16batch/s, Loss=0.705, Acc=0.717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "Train Loss: 0.7051 Acc: 0.7165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Validation: 100%|██████████| 67/67 [00:18<00:00,  3.55batch/s, Loss=0.608, Acc=0.762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6085 Acc: 0.7617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Training: 100%|██████████| 265/265 [02:05<00:00,  2.12batch/s, Loss=0.653, Acc=0.74] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20\n",
      "Train Loss: 0.6534 Acc: 0.7395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Validation: 100%|██████████| 67/67 [00:19<00:00,  3.49batch/s, Loss=0.569, Acc=0.777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5688 Acc: 0.7769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Training: 100%|██████████| 265/265 [02:04<00:00,  2.12batch/s, Loss=0.617, Acc=0.754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "Train Loss: 0.6173 Acc: 0.7545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Validation: 100%|██████████| 67/67 [00:18<00:00,  3.54batch/s, Loss=0.566, Acc=0.779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5660 Acc: 0.7792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Training: 100%|██████████| 265/265 [02:04<00:00,  2.13batch/s, Loss=0.583, Acc=0.771]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20\n",
      "Train Loss: 0.5833 Acc: 0.7711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Validation: 100%|██████████| 67/67 [00:18<00:00,  3.68batch/s, Loss=0.542, Acc=0.791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5416 Acc: 0.7906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Training: 100%|██████████| 265/265 [02:09<00:00,  2.05batch/s, Loss=0.557, Acc=0.787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20\n",
      "Train Loss: 0.5573 Acc: 0.7868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Validation: 100%|██████████| 67/67 [00:21<00:00,  3.08batch/s, Loss=0.528, Acc=0.797]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5281 Acc: 0.7972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Training: 100%|██████████| 265/265 [02:10<00:00,  2.03batch/s, Loss=0.527, Acc=0.798]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "Train Loss: 0.5272 Acc: 0.7979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Validation: 100%|██████████| 67/67 [00:18<00:00,  3.71batch/s, Loss=0.533, Acc=0.789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5331 Acc: 0.7887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Training: 100%|██████████| 265/265 [02:03<00:00,  2.15batch/s, Loss=0.514, Acc=0.806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20\n",
      "Train Loss: 0.5137 Acc: 0.8058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Validation: 100%|██████████| 67/67 [00:17<00:00,  3.84batch/s, Loss=0.515, Acc=0.802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5148 Acc: 0.8017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Training: 100%|██████████| 265/265 [02:03<00:00,  2.15batch/s, Loss=0.503, Acc=0.806]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20\n",
      "Train Loss: 0.5032 Acc: 0.8056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Validation: 100%|██████████| 67/67 [00:17<00:00,  3.79batch/s, Loss=0.535, Acc=0.795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5347 Acc: 0.7950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Training: 100%|██████████| 265/265 [02:04<00:00,  2.12batch/s, Loss=0.478, Acc=0.817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "Train Loss: 0.4782 Acc: 0.8172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Validation: 100%|██████████| 67/67 [00:17<00:00,  3.80batch/s, Loss=0.514, Acc=0.805]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5145 Acc: 0.8050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Training: 100%|██████████| 265/265 [02:01<00:00,  2.19batch/s, Loss=0.47, Acc=0.82]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20\n",
      "Train Loss: 0.4699 Acc: 0.8198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Validation: 100%|██████████| 67/67 [00:19<00:00,  3.51batch/s, Loss=0.516, Acc=0.801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5157 Acc: 0.8007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Training: 100%|██████████| 265/265 [01:57<00:00,  2.25batch/s, Loss=0.461, Acc=0.824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20\n",
      "Train Loss: 0.4606 Acc: 0.8235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Validation: 100%|██████████| 67/67 [00:17<00:00,  3.90batch/s, Loss=0.505, Acc=0.807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5054 Acc: 0.8073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Training: 100%|██████████| 265/265 [01:53<00:00,  2.33batch/s, Loss=0.449, Acc=0.827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "Train Loss: 0.4485 Acc: 0.8273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Validation: 100%|██████████| 67/67 [00:17<00:00,  3.84batch/s, Loss=0.513, Acc=0.802]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5126 Acc: 0.8019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Training: 100%|██████████| 265/265 [01:58<00:00,  2.24batch/s, Loss=0.432, Acc=0.835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20\n",
      "Train Loss: 0.4322 Acc: 0.8347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Validation: 100%|██████████| 67/67 [00:17<00:00,  3.77batch/s, Loss=0.521, Acc=0.801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5208 Acc: 0.8012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Training: 100%|██████████| 265/265 [02:00<00:00,  2.20batch/s, Loss=0.425, Acc=0.84] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20\n",
      "Train Loss: 0.4247 Acc: 0.8396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Validation: 100%|██████████| 67/67 [00:18<00:00,  3.70batch/s, Loss=0.496, Acc=0.811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4958 Acc: 0.8109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Training: 100%|██████████| 265/265 [02:07<00:00,  2.08batch/s, Loss=0.417, Acc=0.842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      "Train Loss: 0.4171 Acc: 0.8422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Validation: 100%|██████████| 67/67 [00:17<00:00,  3.74batch/s, Loss=0.503, Acc=0.808]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5027 Acc: 0.8078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Training: 100%|██████████| 265/265 [02:09<00:00,  2.04batch/s, Loss=0.402, Acc=0.851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "Train Loss: 0.4016 Acc: 0.8506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Validation: 100%|██████████| 67/67 [00:18<00:00,  3.66batch/s, Loss=0.5, Acc=0.818]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.4998 Acc: 0.8179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Training: 100%|██████████| 265/265 [01:53<00:00,  2.33batch/s, Loss=0.391, Acc=0.855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20\n",
      "Train Loss: 0.3914 Acc: 0.8548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Validation: 100%|██████████| 67/67 [00:17<00:00,  3.85batch/s, Loss=0.529, Acc=0.807]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.5288 Acc: 0.8066\n",
      "Early stopping triggered!\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "patience = 3\n",
    "model_save_path = 'COVID-19_Radiography_Dataset/models/best_model_lbp.pth'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  running_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.train()\n",
    "  \n",
    "  train_progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", unit=\"batch\")\n",
    "  for inputs, labels in train_progress:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "\n",
    "    train_progress.set_postfix({\"Loss\": running_loss / total, \"Acc\": correct / total})\n",
    "\n",
    "  epoch_loss = running_loss / len(train_loader.dataset)\n",
    "  epoch_acc = correct / total\n",
    "\n",
    "  print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "  print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "  # wandb.log({\"epoch\": epoch + 1, \"train_loss\": epoch_loss, \"train_accuracy\": epoch_acc})\n",
    "\n",
    "  model.eval()\n",
    "  val_loss = 0.0\n",
    "  val_correct = 0\n",
    "  val_total = 0\n",
    "\n",
    "  # Validation phase with progress bar\n",
    "  val_progress = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\", unit=\"batch\")\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in val_progress:\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "      outputs = model(inputs)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      val_loss += loss.item() * inputs.size(0)\n",
    "      _, predicted = torch.max(outputs, 1)\n",
    "      val_total += labels.size(0)\n",
    "      val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "      val_progress.set_postfix({\"Loss\": val_loss / val_total, \"Acc\": val_correct / val_total})\n",
    "\n",
    "  val_loss = val_loss / len(val_loader.dataset)\n",
    "  val_acc = val_correct / val_total\n",
    "\n",
    "  print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
    "\n",
    "  # wandb.log({\"epoch\": epoch + 1, \"val_loss\": val_loss, \"val_accuracy\": val_acc})\n",
    "\n",
    "  # Check for improvement\n",
    "  if val_loss < best_val_loss:\n",
    "    best_val_loss = val_loss\n",
    "    epochs_no_improve = 0\n",
    "    torch.save(model.state_dict(), model_save_path)  # Save the best model\n",
    "  else:\n",
    "    epochs_no_improve += 1\n",
    "\n",
    "  if epochs_no_improve >= patience:\n",
    "    print(\"Early stopping triggered!\")\n",
    "    break\n",
    "\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
